app:
  PORT: 8080

simulation:
  time_step: 0.1                           # s
  max_steps: 10000                         # Max steps per episode before truncation
  speed: 1                                 # Speed of simulation (for visualization, not RL training)
  loop: false

environment:
  gravity: -9.81                           # m/s²
  air_density: 1.225                       # kg/m³
  num_rockets: 2

landing:
  thresholds:
    perfect:
      speed_vx: 30.0                       # m/s
      speed_vy: 30.0                       # m/s
      angle: 5.0                           # degrees
    good:
      speed_vx: 40.0                       # m/s
      speed_vy: 40.0                       # m/s
      angle: 8.0                           # degrees
    ok:
      speed_vx: 50.0                       # m/s
      speed_vy: 50.0                       # m/s
      angle: 10.0                          # degrees

rocket:
  thrust_power: 10000000                    # N
  cold_gas_thrust_power: 70000             # N
  fuel_consumption_rate: 1700              # kg / (s * throttle)
  radius: 1.85                             # m
  reference_area: 10.8                     # m²
  drag_coefficient: 0.8
  cold_gas_moment_arm: 1.85                # m
  angular_damping: 0.05

  position_limits:                         # meters
    x: [-1500.0, 1500.0]
    y: [1800.0, 2200.0]
  velocity_limits:                         # m/s
    vx: [-25.0, 25.0]
    vy: [-200.0, -150.0]
  acceleration_limits:                     # m/s² (Initial only, not enforced during sim)
    ax: [-5, 5]
    ay: [-5, 5]
  attitude_limits:                         # degrees
    angle: [-15, 15]
    angular_velocity: [-10.0, 10.0]
  mass_limits:
    dry_mass: [34000, 38000]               # kg (dry mass of the booster)
    fuel_mass: [370000, 410000]            # kg (initial fuel mass)

rl:
  tip_over_angle: 10
  max_horizontal_position: 1000
  max_altitude: 1000

  rewards:
    landing_perfect: 1000.0
    landing_good: 500.0
    landing_ok: 100.0
    crash_ground: -300.0
    out_of_bounds: -100.0
    tipped_over: -200.0
    time_penalty: -0.01
    gamma: 0.99

  training:
    total_timesteps: 1000000
    eval_episodes: 10
    save_interval: 50000
    log_interval: 1000

    algorithm:
      PPO:
        learning_rate: 0.0003
        batch_size: 64
        n_steps: 2048
        gamma: 0.99
        ent_coef: 0.01
        n_epochs: 10
        gae_lambda: 0.95
        max_grad_norm: 0.5
        clip_range: 0.2

      SAC:
        learning_rate: 0.0003
        batch_size: 256
        buffer_size: 1000000
        gamma: 0.99
        tau: 0.005
        ent_coef: "auto"
        target_update_interval: 1
        train_freq: 1
        gradient_steps: 1
        learning_starts: 10000

      TD3:
        learning_rate: 0.001
        batch_size: 100
        buffer_size: 1000000
        gamma: 0.99
        tau: 0.005
        policy_delay: 2
        target_policy_noise: 0.2
        noise_clip: 0.5
        train_freq: 1
        learning_starts: 10000
